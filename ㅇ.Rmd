---
title: "SimpleLinearRegression"
author: "R-korea"
date: "2017년 9월 12일"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

#Linear regerssion

지도학습의 단순한 접근법 중 하나
quantitive response를 predict 하는데 유용한 도구임

다른 statistical learning 방법들이 선형모형의 일반화 혹은 확장임
복잡한 것들을 이해하기 전에 선형 모형부터 제대로 이해하고 가는게 좋음!

이번 챕터에서는 선형모형의 key ideas와 모델 fit에 주로 사용되는 least squre approach에 관해 알아봄...

**통계학자 입장에서 어떻게 해야 높은 제품 판매를 보일 수 있을까?**

 ![](\Users\loveactualry\Pictures\various\20170911_1.PNG)

*몇가지 관점들*

1. Is there a relationship between advertising budget and sales?
==> expenditure와 sales가 관계가 있을까?
  만약 관계가 약하다면, 돈을 쓸 이유가 없다~~

2. How strong is the relationship between advertising budget and sales?
==> 

3. Which media contribute to sales?
==> Tv, radio, newspaper 어떤것이..? 전부?!

4. How accurately can we estimate the effect of each medium(광고매체) on sales?
==> 각 매체별로 예측이 얼마나 정확할까?

5. How accurately can we predict future sales?

6. Is the relationship linear?
==> adverstiing과 expenditure사이에서 straight-line관계일까?
predictor or response를 바꿔 사용하는게 가능?

7. Is there synergy among the advertising media?
==> 50,000을 소비했는데 100,000을 얻었다. 상호작용 효과!

##3.1 Simple Linear Regression

Very straightforward approach

Y: a quantitative response
X: single predictor variable

X와 Y사이에 approximately한 선형관계가 있다.

$$Y \approx \beta_0 + \beta_1 X.$$

** regressing Y on X **

For example

$$sales \approx \beta_0 + \beta_1 \ X \ TV.$$


 $\beta_0$ 와 $\beta_1$은 unknown constants. intercept and slope.
 Coefficients or parameters!!!!
 
 만약에 predict라고 한다면 
 
 
$$\hat{y} \approx \hat{\beta_0} + \hat{\beta_1}x.$$

**forecast와 predict의 차이는?**
forecast: 예상하는 것에 대한 추측
predict: 과거의 사실 경헝듬에 입각한 추론에 의한 예언

###3.1.1 Estimaing the Coefficients

  ($x_1$,$y_1$), ($x_2$,$y_2$),...,($x_n$,$y_n$)
  
개별 마켓별 200개 관찰 데이터가 존재
TV advertising and product sales

$\hat{\beta_0}$ 와 $\hat{\beta_1}$를 estimate가 목적!

데이터에 가능한한 근접한 line을 찾는 것!

Least squre를 최소화 하는 방법을 사용한다. 가장 대중적인 접근법.


 ![](\Users\loveactualry\Pictures\various\20170911_2.PNG)
 
 
 
 $\hat{y_i}$ = $\hat{\beta_0}$ + $\hat{\beta_1}$$x_i$ ==> ith based on the ith value of X
 
 $e_i$ = $y_i$\-$\hat{y_i}$ ==> ith residual
 
 $$RSS = e^2_1 +e^2_2 +...+e^2_n,$$
 $$RSS = (y_1-\hat{\beta_0}-\hat{\beta_1}x_1)^2 + (y_2-\hat{\beta_0}-\hat{\beta_1}x_2)^2 +...+(y_n-\hat{\beta_0}-\hat{\beta_1}x_n)^2$$
 
 
 RSS를 최소화 하는 $\hat{\beta_0}$ 과 $\hat{\beta_1}$를 선택한다.
 
 ![](\Users\loveactualry\Pictures\various\20170911_3.PNG)
 
 
 
 위식은 the least squares coefficient estimates for simple linear
regression.


$\hat{\beta_0}$  = 7.03, $\hat{\beta_1}$ = 0.0475

이것을 해석해본다면!!!!!!!

*tv광고비로 추가적으로 $1,000을 소비한다면 47.5게 정도 제품이 더 팔린다.
라고 할 수 있다.*

 ![](\Users\loveactualry\Pictures\various\20170911_4.PNG)
 

### 3.1.2 Assesing the Accuracy of the Coefficient Estimates


  Y=f(X)+ $\epsilon$ ( $\epsilon$ -> mean-zero random error term)

$$Y \approx \beta_0 + \beta_1 X + \epsilon.$$
 (population regerssion line)
 
 $\beta_0$ is intercept term ( when X=0, expected value of Y)
 
 
 $\beta_1$ the average increase in Y associated with a one-unit
increase in X. -> X가 한단위 증가 시 Y의 증가량

**error term은 X에 독립적이라고 가정한다!**

Population regression line -> true relationship between X and
Y


Least squares line -> The least squares regression coefficient estimates


 ![](\Users\loveactualry\Pictures\various\20170911_5.PNG)
 
*left side*


Red line -> true relationshop, 실제 데이터가 아님. 관측되지 않음

Blue line -> 관측치를 least square line을 사용해 계산 가능.


*right side*


10개의 다른 data set형성, slightly different least squares line 생성.
populaton regression line(blue line) 변화 없음.


**이 두개는 왜 다를까?**

나중에~~~~~


how accurate is the sample mean 	$\hat{\mu}$ as an estimate of μ?

=> We have established that the average of $\hat{\mu}$’s over many data sets will be very close to μ. 

그러나 single $\hat{\mu}$의 경우는 over혹은 under estimate할 가능성이 있다.

해결하기 위해


  *stard error* of $\hat{\mu}$ 을 계산한다.

$$Var(\hat{\mu}) = SE(\hat{\mu})^2 = \frac{\sigma^2}{n}$$

$\sigma$ is the standard deviation of each of the realizations $y_i$ of $Y^2$.

standard error는 실제 평균과 추정 평균의 차이의 합의 평균으로 말할 수 있다.

추정치와 실제값이 어떻게 가까워질까?


 ![](\Users\loveactualry\Pictures\various\20170911_6.PNG)

Where $\sigma^2$ = Var($\epsilon$)

SE($\hat{\beta_1}$)

SE($\hat{\beta_0}$)

SE($\hat{\mu}$)

$\sigma^2$을 모를 때, RSE = $\sqrt{\frac{RSS}{(m-2)}}$

엄격하게 얘기하자면 $\hat{SE}(\hat{\beta_1})$ 이지만 "hat"을 drop도 가능


**standard error를 confidence intervals로 사용 가능**

$$ \hat{\beta_1} \pm 2\cdot SE(\hat{\beta_1})$$

95% 신뢰구간으로 본다면
$$ [\hat{\beta_1} - 2\cdot SE(\hat{\beta_1}),\hat{\beta_1} + 2\cdot SE(\hat{\beta_1})]$$


$$ \hat{\beta_0} \pm 2\cdot SE(\hat{\beta_0})$$

$\beta_0$ is [6.130,7.935] and $\beta_1$ is [0.042,0.053].


**Standard errors can also be used to perform hypothesis tests on the hypothesis coefficients.**

계수의 검증 단계

.
 ![](\Users\loveactualry\Pictures\various\20170911_7.PNG)
 
 
 
$$Y \approx \beta_0 + \beta_1 X + \epsilon.$$


t 통계량을 계산해서 귀무가설 기각을 결정한다.

t = $\frac{\hat{\beta_1}-0}{SE(\hat{\beta_1})}$


bell shape & greater than 30......

p-value 사용.

p-value가 작다면  predicotr와 response가 연관이 있다고 볼 수 있다. 즉 귀무가설 기각.


```{r regression}
library(MASS)
library(ISLR)

```


```{r regression1}
lm.fit=lm(medv~lstat,data=Boston)
summary(lm.fit)
```





##3.1.3 Assesing the Accuracy of the Model


선형회귀 적합도의 quality는 *residual standard error*(RSE) and *\R^2* 통계량으로 평가

**Residual Standard Error**


$\epsilon$때문에 regression line을 알더라도 X로부터 Y를 완벽하게 추정할 수는 없음....

RSE는 $\epsilon$의 standard deviation. 

it is the average amount that the response will deviate from the true regression line.


$$ RSE = \sqrt(\frac{1}{n-2}) = \sqrt(\frac{1}{n-2}\sum^n_{i=1} \left(y_i-\hat{y_i}\right)^2)$$
n-2 -> 추정된 모수가 2개이기 때문.(자유도의 개념)


$$ RSS = \sum^n_{i=1} \left(y_i-\hat{y_i}\right)^2)$$


*표준편차: 모집단에 속한 다른 숫자들이 모평균과 차이나는 평균적인 정도*


*표준오차: 뽑힌 표본집단들이 모집단을 추정하기에 적절한지 어떻게 알 수 있을까?*
*매번 뽑히는 여러 표본 평균들의 변동, 편차를 가지는가? -> 표본평균들의 표준편차*


 ![](\Users\loveactualry\Pictures\various\20170911_8.PNG)






RSE는 3.26 -> 각 마켓에서 실제 매출은 약 3260단위로 true regression line으로 부터 벗어남!



다르게 생각해본다면!!!!!


$\beta_0$ $\beta_1$을 정확히 알더라도 여전히 3260단위이다. 이것이 허용가능한지는 상황마다 다르다!



all market is approximately 14,000. error is 3,260/14,000 = 23%




**RSE는 $Y = \beta_0 + \beta_1 X + \epsilon$ 의 lack of fit의 측정도구**


RSE가 작다면 모델과 데이터가 아주 잘 fit 되었따고 결론내릴 수 있다!!!!!!


만약에 $\hat{y_i}$가 $y_i$로부터 멀리 떨어져 있다면 RSE가 많이 커질 수 있다.



모델이 데이터에 잘 안맞다고 할 수 있다.





** $R^2$ Statistic **

RSE는 Y의 단위로 측정이 되기 때문에 항상 좋은 측정이 될 수는 없다. 



$R^2$가 대체가 될 수 있다. -> 1. 분산의 비율로 설명된다. 2. Y의 scale에 독립적 3. 0~1 사이





$$ R^2 = \frac{회귀모형에 의해 설명되는 변동}{총변동} = \frac{TSS-RSS}{TSS} = 1 -\frac{RSS}{TSS}$$



TSS: 총변동


RSS: 오차제곱합. 회귀모형으로 설명되지 못하는 변동


TSS - RSS = 회귀 분석으로 설명되는 variability.


$R^2$는 X로 설명할 수 있는 Y의 변동성 비율을 측정.


범위: 0 ~ 1.


1에 가까워질수록 변동성 비율이 커져 회귀모형의 설명력이 높다!



ex: Table 3.2의 $R^2$가 0.61이면 sales의 2/3만이 Tv의 선형 회귀선을 설명할 수 있고 나머지 1/3설명할 수 없다는 의미.



설명하지 못하는 부분은 새로운 독립변수를 추가하여 설명할 수 있다.


*correlation*


X와 Y의 선형관계를 측정. $R^2$와 $r^2$의 값은 선형회귀에서 같다.


두 변수간의 선형관계에서 방향과 강도를 측정하는 수치.


 ![](\Users\loveactualry\Pictures\various\20170911_9.PNG)





